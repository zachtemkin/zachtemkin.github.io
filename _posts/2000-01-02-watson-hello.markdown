---
layout: project
title: "IBM – Watson Hello"
ID: "ww"
img: "/assets/img/thumbnails/ww-thumb.png"
imgBg: true
brief: "Showcase the value of Watson language processing APIs through a translation experience on a mobile device."
roles: "Ux Design; Prototyping; User Research"
---

In the fall of 2015 I participated in a 12 week design bootcamp as part of my on-boarding to IBM Design. For the first four weeks, I was on a team assigned to create a proof of concept that showcased the value of Watson language processing APIs.

I was one of three UX designers. The rest of the team was made up of two visual designers, one researcher, and one front-end developer. However, even though we had defined roles, we all participated in research activities. I also worked closely with our developer later in the project to produce our prototype using Facebook’s Origami library for Quartz Composer.

##  The Brief

At the start of the project we were introduced to stakeholders from the Watson organization. They gave us some background on the technology and the goals of the project. IBM uses statements called ‘Hills’ to help teams align around goals. Hills are statements of intent written as meaningful user outcomes. Our stakeholders gave us the hill:

	"A consumer can communicate in-person with non-native speakers with their mobile device at the speed of thought, and give Watson feedback along the way.”

From here we began to list out any assumptions we felt were built into the hill and began to find people to interview.

[photo of stickies and pic of assumptions slide]

## Observe & Reflect

### User Interviews

In order to create something that had real value to a user and that stood out in the market we needed to quickly develop a deep understanding of people who need translation services as part of their day-to-day.  

As a team, we found several people whose need for translation was extreme. We interviewed doctors and nurses working in developing countries where they didn’t speak the native language. We spoke with peace corps volunteers working on community development projects where they did not speak the native language. Finally we talked with some IBMers in offices around the world who have to communicate in a non-native language as part of their job.

### Personas & Insights

We synthesized our findings into three personas: the Doctor, the Volunteer, and the Knowledge Worker. As a team we mapped the major pain points of each

[stickies, quotes and journey map slides] 

We came out of this initial research phase with three main insights into how our users approached translation:

[context, prep, review slides]

## Reflect & Make

### Re-align Goals

Now that we had a good understanding of our users and their pain points we began to develop concepts that would solve their problems. Our first step was to use the insights we’d gained to tweak our hill. We did this as part of a presentation of our findings to our stakeholders to make sure that we were still aligned with the goals of the business. Our new hill read:

	"A user can communicate face to face, naturally and confidently, with a non native speaker using a mobile device."

We felt the language in this statement highlighted the importance of maintaining natural, human conversation even though a piece of technology was acting as a facilitator. 

### Concept Generation

Next we began to work to map our insights to concepts. We used the findings from our research to create needs statements for each persona. A needs statement represents a problem faced by a user in the form of an outcome they wish to achieve, e.g. *“Marion the knowledge worker needs to feel confident in the validity of a translation so that she can keep her focus on the task at hand”* 

[picture of needs statements] 

We then each created brief storyboards, or vignettes that represented ideal scenarios for our users. 

[pictures of concepts]

From this work we synthesized three core concepts we wanted in out solution:
- Real time translation (speech to text + text to speech) 
*[only need one device in areas where folks don’t have access to smart phones]*
- Smart Words
- text to text translation 

## Make & Observe 

We quickly created paper prototypes of these concepts to roughly validate our direction with users and stakeholders.

[gif of paper prototypes]

Finally it was time to start creating higher fidelity wire-frames and ultimately putting together a prototype. I lead work on this and ultimately created our demo of the app using quartz composer.

[demo videos] 

## Reflect 

We received a lot of positive feedback at our final demo to our users and stakeholders. Our users felt our solution would definitely help them in their work around the world and our stakeholders were pleased with how our solution demonstrated the power of Watson APIs.

If we could have continued with the project we would have liked to conduct further investigation into issues around the availability of internet and the prevalence of mobile devices in certain regions. We would also have considered how our solution could scale to different device form factors such as wearables and tablets. Finally we would have liked to work more closely with the Watson development team on how data collected through our app could help train the Watson system.


